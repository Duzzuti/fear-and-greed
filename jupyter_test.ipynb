{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all sp500 data for testing\n",
    "import utils\n",
    "import os\n",
    "from sys import exit\n",
    "print(\"Downloading data...\")\n",
    "if not os.path.exists(\"test_data/sp500_possible_replacements.csv\"):\n",
    "    utils.get_sp500_possible_replacements(\"test_data/\")\n",
    "utils.load_sp500_data(\"test_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the range of dates for each company in the S&P 500\n",
    "import utils\n",
    "import pandas as pd\n",
    "sp500df = utils.get_repo_data(\"sp500_companies.csv\")\n",
    "companies = set()\n",
    "companies_dict = {}\n",
    "for index, row in sp500df.iterrows():\n",
    "    for ticker in row['tickers'].split(\",\"):\n",
    "        if ticker in companies:\n",
    "            continue\n",
    "        companies.add(ticker)\n",
    "        # get last occurrence of the ticker (if it exists in the splitted list)\n",
    "        last_occurrence = sp500df.index[sp500df['tickers'].apply(lambda x: \",\"+ticker+\",\" in x or x.endswith(\",\"+ticker) or x.startswith(ticker+\",\"))].max()\n",
    "        # get the last date of that ticker (the entry after the last occurrence)\n",
    "        if last_occurrence == sp500df.index[-1]:\n",
    "            last_date = None\n",
    "        else:\n",
    "            last_date = sp500df.index[sp500df.index.get_loc(last_occurrence) + 1] - pd.Timedelta(days=1)\n",
    "        companies_dict[ticker] = (index, last_date)\n",
    "\n",
    "# print the dictionary with one entry per line\n",
    "for key, value in sorted(companies_dict.items()):\n",
    "    print(key, \"\\t\", value[0], \"\\t\", value[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the margin stats from the downloaded data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"repoData/margin_stats.csv\", index_col=0)\n",
    "# index to datetime\n",
    "df.index = pd.to_datetime(df.index)\n",
    "#rename column\n",
    "df.replace(np.nan, 0, inplace=True)\n",
    "df = df.rename(columns={\"Debit Balances in Customers' Securities Margin Accounts\":\"Debit\"})\n",
    "df = df.rename(columns={\"Free Credit Balances in Customers' Cash Accounts\":\"Credit Cash\"})\n",
    "df = df.rename(columns={\"Free Credit Balances in Customers' Securities Margin Accounts\":\"Credit Securities\"})\n",
    "try:\n",
    "    df[\"Credit\"] = df[\"Credit Cash\"] + df[\"Credit Securities\"]\n",
    "    df.drop([\"Credit Cash\", \"Credit Securities\"], axis=1, inplace=True)\n",
    "except:\n",
    "    pass\n",
    "# calculate Leverage Ratio\n",
    "df[\"Leverage Ratio\"] = df[\"Debit\"] / df[\"Credit\"]\n",
    "df[\"Leverage Ratio\"] -= 1.5\n",
    "df[\"Leverage Ratio\"] = (np.tanh(df[\"Leverage Ratio\"]*2) + 1) *50\n",
    "# plot the leverage ratio\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df.index, df[\"Leverage Ratio\"])\n",
    "plt.title(\"Leverage Ratio\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Leverage Ratio\")\n",
    "plt.show()\n",
    "# save the leverage ratio\n",
    "#df.to_csv(\"repoData/margin_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def fetch_investor_sentiment_data():\n",
    "    # Fetch sentiment data from AAII\n",
    "    # 1. Check for file in data directory\n",
    "    # TODO validate the dates of the data\n",
    "    # TODO scrape the recent data from the website (https://www.aaii.com/sentimentsurvey/sent_results)\n",
    "    date_parser = lambda x: pd.to_datetime(x, format=\"%m-%d-%Y\", errors='coerce')\n",
    "\n",
    "    aaii_sentiment = pd.read_excel(\"data/downloads/\" + \"sentiment.xls\", index_col=0, parse_dates=True, date_parser=date_parser)\n",
    "    # only keep the 6th column\n",
    "    aaii_sentiment = aaii_sentiment.iloc[:, 5]\n",
    "    # remove all rows after the first NaN in index column\n",
    "    aaii_sentiment = aaii_sentiment.iloc[4:pd.Series(aaii_sentiment.index.isna()[4:]).idxmax() + 4]\n",
    "    aaii_sentiment.ffill(inplace=True)\n",
    "    aaii_sentiment.replace(np.nan, 0, inplace=True)\n",
    "    # normalize with tanh\n",
    "    aaii_sentiment = ((np.tanh(aaii_sentiment * 3) + 1) / 2) * 100\n",
    "    # save the data\n",
    "    aaii_sentiment.to_csv(\"aaii_sentiment.csv\")\n",
    "\n",
    "fetch_investor_sentiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def diff():\n",
    "    df = pd.read_csv(\"backupData/sp500components.csv\", index_col=0)\n",
    "    df_last_components = df.iloc[-1, 0]\n",
    "    df_last_components = df_last_components.split(\",\")\n",
    "    df2 = pd.read_csv(\"data/sp500_companies.csv\")\n",
    "    df2_last_components = df2.iloc[:, 0].to_list()\n",
    "    # calculate the difference between the two lists\n",
    "    if sorted(list(df_last_components)) != sorted(list(set(df_last_components))) or sorted(list(df2_last_components)) != sorted(list(set(df2_last_components))):\n",
    "        raise ValueError(\"The input lists must be sets\")\n",
    "    return (list(set(df_last_components) - set(df2_last_components)), list(set(df2_last_components) - set(df_last_components)))\n",
    "print(diff())\n",
    "def add_change():\n",
    "    change = input(\"Enter a change in the format YYYY-MM-DD;Add1,Add2;Rem1,Rem2:\")\n",
    "    if change.count(\";\") != 2:\n",
    "        print(\"The input must contain two semicolons\")\n",
    "        return\n",
    "    change = change.split(\";\")\n",
    "    change_date = change[0]\n",
    "    add = change[1].split(\",\")\n",
    "    remove = change[2].split(\",\")\n",
    "    df = pd.read_csv(\"backupData/sp500components.csv\", index_col=0)\n",
    "    # last date in the dataframe\n",
    "    last_date = pd.to_datetime(df.index[-1]).date()\n",
    "    change_date = pd.to_datetime(change_date).date()\n",
    "    # if last date is less than the change date\n",
    "    if last_date < change_date:\n",
    "        # get the last row in the dataframe\n",
    "        last_row = df.iloc[-1, 0]\n",
    "        last_row = last_row.split(\",\")\n",
    "        # add the new components\n",
    "        if add != [\"\"]:\n",
    "            last_row.extend(add)\n",
    "        # remove the components\n",
    "        for i in remove:\n",
    "            if not i:\n",
    "                continue\n",
    "            if i not in last_row:\n",
    "                raise ValueError(\"The component to be removed must be in the dataframe\")\n",
    "            last_row.remove(i)\n",
    "        # remove duplicates\n",
    "        last_row = sorted(list(set(last_row)))\n",
    "        # convert the list to a string\n",
    "        last_row = \",\".join(last_row)\n",
    "        # add the new row to the dataframe\n",
    "        df.loc[change_date] = last_row\n",
    "        # save the dataframe\n",
    "        df.to_csv(\"backupData/sp500components.csv\")\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"The date must be later than the last date in the dataframe\")\n",
    "add_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"backupData/sp500components.csv\", index_col=0)\n",
    "df.index = pd.to_datetime(df.index)\n",
    "#df = df.resample(\"D\").ffill()\n",
    "#df = df.iloc[:,0].str.split(\",\", expand=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import utils\n",
    "# data_dir = \"test_data/\"\n",
    "# if not os.path.exists(data_dir):\n",
    "#     os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.fetch_sp500companies_data(data_dir, sp500_dir, \"2019-01-01\", \"2020-01-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from metrics import *\n",
    "import matplotlib\n",
    "matplotlib.use('tkagg')\n",
    "import plotting\n",
    "data_dir = \"test_data/\"\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2024-12-08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMetricsCalculation(metric : Metric, y_axis = [\"left\", \"left\", \"right\"]):\n",
    "    if True:\n",
    "        sp500 = SP500Momentum()\n",
    "        sp500.get()\n",
    "    # plot all stages (data, processed, result)\n",
    "    graph_list = [\n",
    "        #plotting.Graph(metric.data, y_axis=y_axis[0], df_color=\"black\", df_label=\"data\"), \n",
    "        plotting.Graph(metric.processed, y_axis=y_axis[1], df_color=\"blue\", df_label=\"processed\"), \n",
    "        plotting.Graph(metric.result, y_axis=y_axis[2], df_color=\"red\", df_label=\"result\"),\n",
    "        #plotting.Graph(metric.test, y_axis=y_axis[2], df_color=\"blue\", df_label=\"result\"),\n",
    "        #plotting.Graph(sp500.data, y_axis=y_axis[2], df_color=\"green\", df_label=\"train\"),\n",
    "        #plotting.Graph(metric.test, y_axis=y_axis[2], df_color=\"orange\", df_label=\"test\")\n",
    "    ]\n",
    "    plotting.plot_graph(graph_list, neutral_line=None, title=metric.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Metric.setPreferences(data_dir, start_date, end_date)\n",
    "metrics = []\n",
    "metrics.append(T10YearYield())\n",
    "metrics.append(JunkBondSpread())\n",
    "metrics.append(SaveHavenDemand())\n",
    "metrics.append(ConsumerSentiment())\n",
    "metrics.append(SP500Momentum())\n",
    "metrics.append(PutCallRatio())\n",
    "metrics.append(InsiderTransactions())\n",
    "metrics.append(AAIISentiment())\n",
    "metrics.append(MarginStats())\n",
    "metrics.append(VIX())\n",
    "for metric in metrics:\n",
    "    metric.get()\n",
    "    showMetricsCalculation(metric)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
