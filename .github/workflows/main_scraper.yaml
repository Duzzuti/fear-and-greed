name: Scrape Data
on:
  schedule:
    # Runs every day at 11:00 UTC
    - cron: "0 11 * * *"

  workflow_dispatch: # Allows you to manually trigger the workflow

permissions:
  contents: write
  pull-requests: write

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repo
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          sudo apt-get install gh

      # Step 4: Git setup
      - name: Git setup
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git fetch
          git pull || exit 1

      # Step 5: Run the scraper
      - name: Run put call ratio scraper
        run: python scraper/main_scraper.py
      
      # Step 6: Push changes
      - name: Push changes
        run: |
          if [[ -z $(git status --porcelain) ]]; then
            echo "No changes to commit."
          else
            git add -A  # Adds all changes, respecting .gitignore
            git commit -m "Update Data [ci skip]" || echo "No changes to commit, skipping push."
            git push origin main || git push origin main --set-upstream
          fi
